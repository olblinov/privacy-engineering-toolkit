# Week 24-30 April 2023

- **CJEU rules against Deutsche Wohnen in data retention case** (https://curia.europa.eu/juris/liste.jsf?lgrec=fr&td=%3BALL&language=en&num=C-807/21&jur=C): You may remember one of the largest fines (EUR 14.5M to be precise) for data retention mispractices to be the case against Deutsche Wohnen. The fine was rejected by courts due to German law theory that any corporate liability is possible only if attributable to a specific natural person within the organization. GDPR does not require the same. CJEU stated that for GDPR liability to take place, any action by an employee is equally attributable to the legal entity as a whole and no additional criteria need to be fulfilled. 

- **Dark patterns lead an Italian company to a EUR 300k fine for unlawful marketing** (https://www.garanteprivacy.it/web/guest/home/docweb/-/docweb-display/docweb/9870014): Ediscom had a database of 21M people receiving their marketing messages, some of them collected from own website, some lists bought from third parties. Before acquiring lists, Ediscom reviewed consents of source websites, their privacy policies & required proof of consent (IP address, date and time of registration, type of express consent, registration URL). The websites which collected consent in many cases made consent mandatory, had excessive mandatory fields, and even requested contact details of friends who would want to receive marketing materials. 

- **ChatGPT adds option to reject usage of data for training** (https://www.linkedin.com/posts/milanmilanovic_technology-programming-artificialintelligence-activity-7057639589368213505-3XAV): ChatGPT user interfaces has added a flag which reject's OpenAI's use of the data for training.

- **EUR 25k fine in Spain for untelligible and incomplete data provided under a data access request** (https://www.aepd.es/es/documento/ps-00281-2022.pdf): Following a robbery of his home, a person requested information from Securitas Direct Espa√±a which installed an alarm under a service contract with the complainant. The company provided logs in an unorganized, incomplete manner, sometimes lacking a decryption key. Smart way of using one's access rights + another signal that just exporting whatever you've got is a bad idea. 

- **Safe harbour - a viable GDPR/CCPA alternative?** (https://www.linkedin.com/posts/victoriabeckman_nist-privacy-framework-chart-victoria-beckman-activity-7057429779871850496-hv4h): Victoria Beckman on LinkedIn explains that Ohio, Utah and Connecticut have "safe harbour" privacy laws, meaning companies obtain an affermative defense if the company is able to demonstrate that their data security policies followed a recognize standard or framework (e.g. NIST). The same approach is currently being taken by Tennessee which creates incentives for companies to follow a privacy programm which reasonably conforms to NIST privacy framework. Though I wonder how it is supposed to work in practice given that one of the feautures of the NIST framework is that one can choose to implement a portion of it only (so-called profiles).

- **Montana's Consumer Data Privacy Act on Governor's desk to be signed into law** (http://laws.leg.mt.gov/legprd/LAW0210w%24BSIV.ActionQuery?P_BILL_DFT_NO5=LC1086&Z_ACTION=Find&P_SESS=20231): Judging from summaries, the law is very similat to CCPA. It is also a part of the overall US wave of state consumer privacy laws.

- **Using a black marker to redact scans is not anonymization** (https://www.garanteprivacy.it/web/guest/home/docweb/-/docweb-display/docweb/9870171): An Italian company ASL published reviews ASL received from its former patients. Such reviews contained medical history, diagnoses etc. The contact details of the patients were struck out with a black marker, which howere still allowed reading the letters behind it. Consequently, ASL was found publishing medical data and fined EUR 50k for it.