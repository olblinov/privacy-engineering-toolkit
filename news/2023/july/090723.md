# Week 3-9 July 2023

- ‚úÖüá™üá∫üá∫üá∏ **EU Member States vote YES on EU-US Data Privacy Framework** (https://ec.europa.eu/transparency/comitology-register/screen/documents/091061/1/consult?lang=en): The effective date of the EU-U.S. DPF Principles is the date of entry into force of the European Commission‚Äôs adequacy decision for the EU-U.S. DPF. I don't expect this to take long. An interesting question if the adequacy decision will mean an automatic relief for Meta's troubles after the DPC's decision to prohibit transfers. My reading of section 9.51 of the DPC decision (https://edpb.europa.eu/system/files/2023-05/final_for_issue_ov_transfers_decision_12-05-23.pdf) is that it automatically lifts the suspension order when the DPF is in force: "*the orders specified in Section 10, below, will remain effective unless and until the matters giving rise to the finding of infringement of Article 46(1) GDPR have been resolved, including by way of new measures, not currently in operation, such as the possible future adoption of a relevant adequacy decision by the European Commission pursuant to Article 45 GDPR*." (note the "unless and until" part).

- ‚öñÔ∏èüîíüíº **CJEU's finds Meta's legal basis for ads can only be consent** (https://curia.europa.eu/jcms/upload/docs/application/pdf/2023-07/cp230113en.pdf, https://curia.europa.eu/juris/document/document.jsf?text=&docid=275125&pageIndex=0&doclang=EN&mode=req&dir=&occ=first&part=1&cid=541739):
  - A while ago, the German Federal Cartel Office started investigating Meta abuse of dominant position for processing German resident's data based on general terms instead of consent (para 29). Meta relied on this basis to process both data on Facebook, as well as off-Facebook data collected by users of Facebook Business Tools via pixels and similar tech (para 28). 
  - Notable points in CJEU's decision:
    - The antitrust authority is able to note the non-compliance with GDPR for the sole purpose of establishing an abuse of a dominant position (para 49) as long as it sincerely cooperates with the lead DPA (para 53).
    - Data stemming from thematic sources (e.g. political party websites, health-relating websites, gay dating sites etc.)  does not automatically constitute sensitive data; instead, the courts should assess the qualification of data on a case-by-case basis (para 72). The mere visit of a website does not constitute manifestly making the data public (exception under Art. 9(2)(e)) (para 78). Tapping on "Share" or "Like" can only be considered as making the data public if express information was provided beforehand (para 83).
    - Legal basis considerations:
      - Personalised content does not appear to be necessary in order to offer that user the services of the online social network (paras 101-103) => performance of contract legal basis does not fit;
      - Despite the fact that the services of an online social network such as Facebook are free of charge, the user of that network cannot reasonably expect that the operator of the social network will process that user‚Äôs personal data, without his or her consent, for the purposes of personalised advertising (para 117). This is also influenced by the fact that "*processing at issue in the main proceedings is particularly extensive since it relates to potentially unlimited data and has a significant impact on the user, a large part ‚Äì if not almost all ‚Äì of whose online activities are monitored by Meta Platforms Ireland, which may give rise to the feeling that his or her private life is being continuously monitored*" (para 118).
      - Use of the data for product improvement based on legitimate interest is also doubtful, "*given the scale of that processing and its significant impact on the user, as well as the fact that the user cannot reasonably expect those data to be processed*".
    - Practical outputs:
      - More sources of risk: not only DPAs, but also antitrust authorities can assess GDPR compliance;
      - Consent for marketing: I expect Meta to start enforcing consent collection on use of its products;
      - Shaky ground for product improvement: While the CJEU appears to be in more doubt about LI for product improvement rather than marketing, it did not provide any objective thresholds for "given the scale". 
      - DPA focus on purposes rather than details: Following the above point, the CJEU did not provide any objective description of the threshold when processing is excessive and requires consent. This will allow DPAs to just refer to this CJEU judgement and wholesale prohibit LI-based marketing and product improvement.

- üí∞üö´üïµÔ∏è‚Äç‚ôÇÔ∏è**Sweden's ‚Ç¨1M enforcement against use of GA** (https://edpb.europa.eu/news/national-news/2023/imy-orders-cdon-coop-dagens-industri-and-tele2-stop-using-google-analytics_en, https://www.imy.se/globalassets/dokument/beslut/2023/beslut-tillsyn-ga-tele2.pdf, https://www.imy.se/globalassets/dokument/beslut/2023/beslut-tillsyn-ga-cdon.pdf): 4 companies were investigated based on NOYB's complaints relating to the use of the Google Analytics tool. Each of the 4 decisions are a bit different, so I'll concentrate on the Tele2 one and add some notable differences about the others. The controller integrated a GA pixel which sent (1) user surfing events (pages + clicks); (2) device informaiton (dynamic IP anonymized after collection by dropping the last octet + browser type, OS, screen resolution, language, timestamp); (3) _ga cookie value. The DPA made the following judgements:
  - **The information concerned constitutes personal data**: The cookie itself, or combined with other data would amount to personal data, regardless of whether Google or Tele2 intend to identify the data subject. As to the dynamic IP address, the DPA says that the CJEU's MICM and Breyer judgments should be read as saying that a dynamic IP address is personal data if there is a legal possibility to obtain access to supplementary information for the purpose of identifying the complainant as opposed to proving a legal possibility to address the ISP for additional data. In other words, the ISP is not the only venue to obtain supplementary information, and therefore the dynamic IP address is personal data as it can be combined with other data points collected (see above) and constitutes personal data. Best case, a dynamic IP is pseudonymised data. 
  - **Prohibited transfers to the US**: The DPA considered the safeguards provided by Google to be ineffective as they did not directly address the main problem of US law obligating Google to disclose data upon request. E.g. careful examining of inbound requests for legality does not address the underlying inadequacy of the US law in quesiton. It appears that the now usual no-risk-allowed approach was taken. Worryingly, the DPA in fleeting also says that UUID have the "specific purpose of distinguishing users" and are personal data (though the DPA says so based on the argument of possibility to combine with other data collected). IP address truncation did not move the needle. 
  - **Coop's Server-side container**: This one's hard to read as the DPA seems to copy-paste a lot from other decisions, despite a different background: Coop used a server-side container for the GA script (simply speaking, the GA script file is not fetched by the user's browser from Google's servers, but instead from Coop's server). This means that it does not disclose the user's public IP address (instead, one and the same generic IP address is transferred to Google), but relied upon clientID (to determine if user is new or recurring), userID (granted upon login), gclid and dclid (Google-generated UTMs to denote ad campaigns) & transactionID (order number by coop). For some reason, the DPA refers to "_gads", "_ga" and "_gid" cookies are unique identifiers in it's assessment, though in earlier background sections it did mention them (compare 2.2.2 to 1.3.10). Absurdly, the DPA says that the generic IP address (the one shared by ALL visitos of coop.se) is pseudonymised data is it allows Google to make the link between the data entry and Coop (so what?). Despite the IP anonymization, the unique identifiers (clientID, userID, gclid and dclid as well as transactionID) are also transmitted and can be connected to other data. The DPA recomments that all unique identifiers should instead be transmitted in a modified form (ie not in plain text), which means that transmitted data cannot be linked.

- üìäüë•üíº **IAPP & KPMG Privacy Risk Study 2023** (https://iapp.org/resources/article/privacy-risk-study/): KPMG and IAPP have released a study on privacy risk management across demographics. Notable findings:
  - **Risk management baselines**:
    - Only 50% of organizations have an established privacy risk appetite
    - 64% of organizations have a privacy risk management program that is fully integrated into their overall enterprise risk management program
    - 83% of organizations place some kind of privacy risk information in their annual report
    - Almost 93% of organizations indicated privacy is a top-10 organizational risk, and 36% ranked it within the top five.
  - **Consumer pressure**: The 2023 IAPP Privacy and Consumer Trust Report revealed nearly 68% of consumers are either somewhat or very concerned about their online privacy. The report also found more than 60% of consumers have an actionable defensive response, e.g., deleting an app off their phone when concerned about privacy, and 34% switch companies after they suffer a data breach.
  - **Top risks perceived by stakeholders**:
    - 1.  Personal data breaches (average priority: 2)
    - 2.  Additional privacy risk due to the non-compliant processing of personal data by its third parties (average priority: 3)
    - 3.  Privacy considerations are not effectively integrated into product design (average priority: 4)
    - 4.  Incomplete identification, mapping and resulting management of personal data (average priority: 4)
    - 5.  Employee training (average priority: 4)
    - 6.  Inability to meet requirements due to differing and/or evolving requirements across various regulatory regimes (average priority: 5)
    - 7.  Inability to identify, quantify and/or prioritize privacy risk (average priority: 5)
    - 8.  Lack of privacy resources and/or budget (average priority: 6)
    - 9.  Inability to meet business objectives due to the pursuit of business profits/objectives not being balanced against risk of underlying personal data processing activities (average priority: 7)
    - 10. Overlaps between teams create inefficiencies in meeting privacy compliance requirements, e.g., privacy versus security or privacy legal versus privacy ops (average priority: 7)
  - **Accountability & 3 lines of defense model**: 
    - 3 lines of defense:
      - The first line is responsible for identifying and managing risks in their day-to-day objectives. 
      - The second line provides policies, tools and other support to ensure risk is mitigated effectively and maintain consistency across definitions and measurements of risk. 
      - The third line provides an independent assurance of the first two lines and usually reports to the board or an audit committee.
    - Distribution of respondents across lines of defense:
      - 100% identified roles and responsibilities for privacy risk sit at least in the first line of defense
      - 57% also indicated they have roles and responsibilities set up in the second line of defense
      - 21% of organizations empowered the third line of defense to undertake privacy audits
  - **Approaches to risk management**:
    - Frameworks:
      - ISO 31000: Risk management ‚Äî Guidelines + ISO/IEC 27557: Application of ISO 31000:2018 for organizational privacy risk management
      - NIST Risk Management Framework + NIST Privacy Framework 
    - By far the most common was the five-by-five risk matrix which plots the likelihood of a risk occurring against the severity of the risk if it occurs.
    - 71% of interviewees in this study noted their organizations established strong audit capabilities, but the catalyst and scope of their audits differed slightly depending on the organization. For some the scope is a series of generalized risk-related questions, whereas others have a scope that is privacy risk-specific and identified through risk assessments.
  - **AI**: The risk environment is likely to get even more complex. As organizations integrate AI into products and services, AI privacy risk management is one area that is likely to require further consideration. Solutions:
    - privacy by design (through the use of resources like ISO 31700, for example)
    - NIST‚Äôs AI Risk Management Framework