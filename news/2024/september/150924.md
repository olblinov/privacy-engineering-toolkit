# September 1-15

- **EU wants to develop SCCs for the specific case where a data importer is located in a third country but is directly subject to the GDPR** (https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14404-Standard-contractual-clauses-for-the-transfer-of-data-to-third-country-controllers-and-processors-subject-to-the-GDPR_en): Standard contractual clauses are model data protection clauses EU data exporters can incorporate into their contracts to transfer personal data to data importers in third countries in line with the requirements of the General Data Protection Regulation (GDPR). These clauses are for the specific case where a data importer is located in a third country but is directly subject to the GDPR. They complement the existing clauses, for data transfers to third country importers not subject to the GDPR.

- **French CNIL fines CEGEDIM SANTÉ for pseudonymous processing of health data** (https://www.cnil.fr/en/health-data-cegedim-sante-fined-eu800000):
  - CEGEDIM SANTÉ publishes and sells management software for general practitioners working in surgery and health centers. Some 25,000 medical practices and 500 health centers use this software. This software enables doctors to manage their diaries, patient files and prescriptions. As part of its business, the company offers a panel of doctors using one of these software packages the opportunity to join an "observatory". Data collected are then used by CEGEDIM SANTÉ's customers, in particular for research purposes.
  - The restricted committee noted that CEGEDIM SANTÉ collected a large amount of data on the individuals concerned, such as year of birth, gender, socio-professional category, allergies, medical history, height, weight, diagnosis, medical prescriptions, sick leaves and analysis results. The data were linked to a unique identifier for each patient of the same doctor, **making it possible to combine data transmitted successively by the same doctor concerning the same patient, and thus to reconstruct their healthcare pathway**. In view of thisinformation, the restricted committee considered that it was possible to isolate an individual within the company's database, and that the company possessed a great deal of particularly detailed information concerning that individual, leading to a risk of re-identification.
  - It noted that consultation of the data from this teleservice by a doctor who was a member of the "observatory" automatically led to the data being downloaded into the patient's computerized file, enabling the company to collect it at the same time. The restricted committee considered that, by not providing for the possibility of data simply being consulted by doctors without leading to an automatic collection, the company had not processed the data lawfully.

- **EUR 8k fine for e-mail spam to one data subject** (https://www.autoriteprotectiondonnees.be/publications/decision-quant-au-fond-n0-108-2024.pdf): An unnamed company was fined by the Belgian Data Protection Authority (DPA) after a complaint about receiving unwanted marketing emails. The complainant had not provided their data to the company and continued receiving emails even after requesting data deletion. The complainant's data was transferred to the company following the bankruptcy of a football club, where the complainant was a subscriber.

- **EUR 25k / day for deceptive cookie banner config**(https://www.gegevensbeschermingsautoriteit.be/gba-neemt-maatregelen-tegen-mediahuis-voor-onrechtmatig-gebruik-van-cookiebanners-op-perssites): The Belgian Data Protection Authority (GBA) took action against Mediahuis, a major media company, for violating rules on cookie banners across its news sites. Mediahuis failed to provide an easily accessible "reject all" option for cookies, used deceptive design choices like button colors to encourage cookie acceptance, and made withdrawing consent unnecessarily complicated. 

- **CJEU AG on Automated Decision Making and disclosure of decision mechanism (complexity, trade secrets)** (https://curia.europa.eu/juris/document/document.jsf?text=&docid=290022&pageIndex=0&doclang=EN&mode=req&dir=&occ=first&part=1&cid=2084344):
  - A mobile telephone operator refused to extend a contract with the customer on the ground that she did not have sufficient financial creditworthiness. CK’s allegedly insufficient creditworthiness was substantiated by an automated credit assessment.  D & B (the operator) challenged the decision of the Austrian data protection authority requiring it to disclose the information requested by CK before the Bundesverwaltungsgericht (Federal Administrative Court, Austria).
  - The crux of the matter is:
    - What constitutes "meaningful information" under Article 15(1)(h) of the GDPR in profiling cases?
    - Must this include details on the algorithm, input data, and parameters used in automated decision-making?
    - How can transparency be balanced with the protection of trade secrets and third-party data?
    - Does Article 15(4) of the GDPR limit access rights if trade secrets are involved?
    - Are national data protection laws (like Austria’s DSG) compatible with the GDPR when limiting access to trade secrets?
  - AG's notable opinions:
    - [34-35] In his Opinion delivered in the case which gave rise to the judgment in SCHUFA Holding and Others  (Scoring), (12) Advocate General Pikamäe expressed a view on the main aspects of those questions. He considered that Article 15(1)(h) of the GDPR, read in conjunction with recital 63 of that regulation, must be interpreted as ‘also covering, in principle, the calculation method used by a credit information agency to establish a score, provided there are no conflicting interests that are worthy of protection’. ... In Advocate General Pikamäe’s view, it follows that ‘while protection of trade secrets or intellectual property in principle constitutes a legitimate reason for a credit information agency to refuse to disclose the algorithm used to calculate the score for the data subject, it cannot under any circumstances justify an absolute refusal to provide information’.
    - [37-38] Advocate General Pikamäe therefore concluded that ‘the obligation to provide “meaningful information about the logic involved” must be understood to include sufficiently detailed explanations of the method used to calculate the score and the reasons for a certain result. In general, the controller should provide the data subject with general information, notably on factors taken into account for the decision-making process and on their respective weight on an aggregate level, which is also useful for him or her to challenge any “decision” within the meaning of Article 22(1) of the GDPR.’ ... I agree, in essence, with the interpretation proposed by Advocate General Pikamäe.
    - [64] The data subject’s knowledge of that context must enable him or her, through knowledge of the essential elements of the method and the criteria used, to understand the result reached by the automated decision. In short, the process, which is technical in nature, that led to that decision must be made intelligible. Only in that way will the data subject be able to exercise his or her rights under the GDPR, including the right to express his or her point of view on an automated decision and the right to challenge it. The concept of ‘meaningful information about the logic involved’ in automated decision-making must therefore be understood functionally. 
    - [71] ... person can obtain information that is concise, easily accessible and easy to understand, and formulated in clear and plain language on the method and criteria used for that decision. In the second place, that information must be sufficiently complete and contextualised to enable that person to verify its accuracy and whether there is an objectively verifiable consistency and causal link between, on the one hand, the method and criteria used and, on the other, the result arrived at by the automated decision.
    - !!! [72] In the light of the foregoing, I do not consider that Article 15(1)(h) of the GDPR must be interpreted as imposing on the controller an obligation to disclose to the data subject information which, by reason of its technical nature, is so complex that it cannot be understood by persons who do not have particular technical expertise. (45) In my view, algorithms used in automated decision-making constitute such information.
    - !!! [74] ‘the controller should find simple ways to tell the data subject about the rationale behind, or the criteria relied on in reaching the decision. The GDPR requires the controller to provide meaningful information about the logic involved, not necessarily a complex explanation of the algorithms used or disclosure of the full algorithm … The information provided should, however, be sufficiently comprehensive for the data subject to understand the reasons for the decision.’ (47) Thus, ‘the controller should provide the data subject with general information (notably, on factors taken into account for the decision-making process, and on their respective “weight” on an aggregate level) which is also useful for him or her to challenge the decision’.
    - !!! [94] I consider that ... where the information which must be provided to the data subject under the right of access guaranteed by the first of those provisions is likely to result in an infringement of the rights and freedoms of others, in particular because it contains personal data of third parties protected by the GDPR or a trade secret, within the meaning of Article 2(1)(1) of Directive 2016/943, that information must be disclosed to the competent supervisory authority or court so that the latter can weigh up, in full knowledge of the facts and in accordance with the principle of proportionality and the confidentiality of that information, the interests involved and determine the extent of the right of access that must be granted to that person.
  - Summary:
    -  that information must enable the data subject to exercise the rights ... It must therefore be concise, easily accessible and easy to understand, and formulated in clear and plain language. In addition, the information must be sufficiently complete and contextualised to enable that person to verify its accuracy and whether there is an objectively verifiable consistency and causal link between, on the one hand, the method and criteria used and, on the other hand, the result arrived at by the automated decision at issue;
    -  the controller is not required to disclose to the data subject information which, by reason of its technical nature, is so complex that it cannot be understood by persons who do not have particular technical expertise, which is such as to preclude disclosure of the algorithms used in automated decision-making;
    -  where the information to be provided to the data subject under the right of access ... is likely to result in an infringement of the rights and freedoms of others, in particular because it contains personal data of third parties protected by that regulation or a trade secret ... that information must be disclosed to the competent supervisory authority or court so that the latter can weigh up, in full knowledge of the facts and in accordance with the principle of proportionality and the confidentiality of that information, the interests involved and determine the extent of the right of access that must be granted to that person.

- **CJEU on whether partners have a right to learn contact details of other partners in a partnership** (https://curia.europa.eu/juris/document/document.jsf?mode=req&pageIndex=1&docid=290003&part=1&doclang=EN&text=&dir=&occ=first&cid=2040209):
  -   It is apparent from the orders for reference that HTB and Ökorenta are investment companies which each hold shares indirectly through a trust company in investment funds.  The applicants in the main proceedings request the defendants in the main proceedings, which are trust companies, to disclose the names and addresses of all their partners with indirect shareholdings in the investment funds concerned, through trust companies. The defendants in the main proceedings object to such a disclosure, taking the view that the data requested are intended to serve the economic interests of the applicants in the main proceedings, consisting in advertising their own investment products, causing concern among investors, or purchasing their shares at a price below their value and making a profit by reselling them.
  -   In accordance with the case-law of the Bundesgerichtshof (Federal Court of Justice), the abuse of rights is, in any event, ruled out where an investor seeks contact with other investors in order to discuss matters concerning the partnership with them and, where appropriate, to organise a commonality of interests between investors. 
  -   Questions:
      -    In the case of a [partnership offering shares for public subscription], a limited partner with negligible liability has a “legitimate interest” in obtaining information relating to all partners with shares held indirectly through a trustee, together with their contact details and the number of their shares in such a partnership, and a contractual obligation to that effect must be inferred from the partnership agreement?
      -    Does the intention to make contact for the purpose of becoming better acquainted, exchanging views or negotiating the purchase of shares in the partnership suffice in order not to exceed the limits to prevent abuse of rights inherent in such an unrestricted right?
 -    CJEU's judgement: 
      -  [46-47] ... it should be noted that the essential feature of acquiring an indirect shareholding, through a trust company, in an investment fund offering shares for public subscription is precisely the anonymity of the partners, including in relations between the partners themselves. ... Accordingly ... the processing of confidential data, consisting in disclosing information concerning partners with indirect shareholdings through a trust company in an investment fund offering shares for public subscription, cannot be regarded as being ‘necessary for the performance of a contract’.
      -  [50] a wide range of interests is, in principle, capable of being regarded as legitimate (judgment of 7 December 2023, SCHUFA Holding (Discharge from remaining debts), C‑26/22 and C‑64/22, EU:C:2023:958, paragraph 76).
      -  [64]  it is necessary to attach particular significance to the fact that it is likely, with regard, in particular, to the contractual provisions referred to in paragraph 45 of this judgment, that the indirect partners of such an investment fund could not reasonably expect, at the time when their personal data are collected, that those personal data are disclosed to third parties, in the present case, to other indirect partners of that investment fund.

- **Guidance on data breach notifications to data subjects** (https://autoriteitpersoonsgegevens.nl/system/files?file=2024-09/Rapportage%20waarschuwingsberichten%20na%20datalekken.pdf, https://autoriteitpersoonsgegevens.nl/themas/beveiliging/datalekken/zo-informeert-u-slachtoffers-over-een-datalek#8-aanbevelingen-voor-goede-waarschuwingsberichten): 
  - Notify victims as soon as possible to allow them to protect themselves from potential misuse of their personal data.
  - Write in clear, simple language to ensure everyone understands the message, avoiding technical jargon unless it is well-explained.
  - Fully describe what happened, including the type of data breach (e.g., ransomware, phishing) and whether personal data was lost or compromised.
  - Specify the leaked data, such as names, email addresses, or identification numbers.
  - Explain the potential consequences of the breach, such as phishing attacks or identity fraud, and give advice on how to mitigate these risks.
  - Provide actionable advice to victims, like changing passwords or reporting identity fraud to the appropriate authorities.
  - Detail the measures taken by the organization to contain the breach and prevent future incidents.
  - Offer a contact point for victims to ask questions or seek further assistance.

- **Excessive biometric data use and storage in employment context** (https://www.autoriteprotectiondonnees.be/publications/decision-quant-au-fond-n0-114-2024.pdf): The Belgian Data Protection Authority (DPA) fined a company €45,000 for GDPR violations involving biometric data collection. The company used employees' fingerprints for time registration without offering an alternative or providing sufficient information on data processing. The DPA found the company failed to obtain valid consent and breached GDPR principles, including purpose limitation, data minimization, and transparency. Key violations were related to Articles 5, 6, 9, and 13 of the GDPR. The company did not properly inform employees or justify its legal basis for processing biometric data.